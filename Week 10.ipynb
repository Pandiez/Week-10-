{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcbceb1a",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "1)Simple Linear Regression (SLR) vs. Multiple Linear Regression (MLR) SLR Model Equation: Y = β0 + β1X In SLR, there is a single predictor variable X used to predict the response variable Y. The term β0 represents the intercept, indicating the expected value of Y when X is zero, while β1 denotes the slope, reflecting how much Y changes with a one-unit increase in X. Example Scenario: Estimating a car's fuel efficiency Y (in miles per gallon) based solely on its weight X (in pounds).\n",
    "\n",
    "MLR Model Equation: Y = β0 + β1X1 + β2X2 + ... + βnXn MLR utilizes multiple predictor variables X1, X2, ..., Xn to better understand the relationship with Y. Advantage of MLR over SLR: MLR can consider various factors affecting Y, which may enhance predictive accuracy and understanding. It also allows for the evaluation of one variable's effect while controlling for another. Example Scenario: Estimating house prices Y based on characteristics such as size X1 (in square feet), number of bedrooms X2, and location X3.\n",
    "\n",
    "2)Continuous Variable vs. Indicator Variable in SLR Continuous Variable: If the predictor variable X is continuous, the model remains: Y = β0 + β1X In this case, Y changes continuously as X varies. Indicator Variable: If X is a binary indicator variable, it takes values of 0 or 1. The model is: Y = β0 + β1D where D is the indicator variable. This indicates: Y = β0 when D = 0, Y = β0 + β1 when D = 1. Example Scenario for Indicator Variable: A study assessing the impact of a treatment where D = 1 if a patient received the treatment and D = 0 otherwise. Here, β1 would indicate the expected change in response Y due to the treatment.\n",
    "\n",
    "3)Combining an Indicator Variable with a Continuous Variable in MLR When both an indicator variable D and a continuous variable X are included in MLR, the model is: Y = β0 + β1X + β2D Model Dynamics: This configuration allows for different intercepts for each group defined by D, while keeping a consistent slope β1 for X across both groups. Interpretation: β0 is the intercept when D = 0, and β2 shows the difference in intercepts between the groups D = 1 and D = 0. Example Scenario: Analyzing salary Y based on years of experience X and gender D (where D = 1 indicates male and D = 0 indicates female). This model accounts for a baseline salary difference between genders while assuming the salary increase per year of experience is uniform.\n",
    "\n",
    "4)Incorporating an Interaction Between a Continuous Variable and an Indicator Variable in Multiple Linear Regression (MLR) When an interaction term is added between a continuous variable XXX and an indicator variable DDD, the model takes the following form: Y = β0 + β1X + β2D + β3(X⋅D) Model Dynamics: The interaction term β3(X⋅D) allows the slope of XXX to vary between the groups where D=1 and D=0. Interpretation: For D=0, the model simplifies to Y = β0 + β1X. For D=1, it becomes Y = (β0 + β2) + (β1 + β3)X, indicating that both the intercept and slope can differ across the groups. Example Scenario: Analyzing the impact of a training program on productivity YYY, where XXX represents years of experience and DDD indicates program participation (1 for participation, 0 for non-participation). This model enables the baseline productivity and the influence of experience on productivity to vary based on whether one participated in the program.\n",
    "\n",
    "5)MLR Model Using Only Indicator Variables from a Non-Binary Categorical Variable For a categorical variable with more than two categories, we create indicator variables for each category, excluding one. If the categorical variable has k levels, we will use k−1 indicator variables, establishing a baseline group represented when all indicator variables are zero. Model Form Example: For a categorical variable with three categories (e.g., A, B, C), we create two indicators: Y = β0 + β1D1 + β2D2 where: D1 = 1 if the category is A, 0 otherwise. D2 = 1 if the category is B, 0 otherwise. When both D1=0 and D2=0, it indicates category C, which serves as the baseline group. Model Dynamics and Interpretation: Baseline Group: The baseline group (C) acts as a reference point. β0 represents the expected value of YYY for this group. Coefficient Interpretation: β1 indicates the expected value difference of YYY between groups A and C, while β2 shows the difference between groups B and C. Example Scenario: Estimating test scores YYY based on the type of educational program with three options (Program A, Program B, and Program C). In this case, Program C is the baseline, and the coefficients β1 and β2 reflect the differences in scores compared to this baseline group. Using \"number of categories minus one\" for indicator variables ensures that each category is distinctly represented in the model while maintaining a full-rank design matrix, thus avoiding redundancy among predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f4b9b",
   "metadata": {},
   "source": [
    "2.\n",
    "\n",
    "1) Identifying Variables, Considering Interactions, and Presenting Linear Equations\n",
    "Variables:\n",
    "Outcome Variable: Sales (Y)\n",
    "Predictor Variables:\n",
    "TV Advertising Expenditure (X1) and Online Advertising Expenditure (X2)\n",
    "Linear Equations:\n",
    "Without Interaction:\n",
    "Y=β0+β1X1+β2X2\n",
    "With Interaction:\n",
    "Y=β0+β1X1+β2X2+β3(X1⋅X2)\n",
    "Explanation of Predictions and Differences:\n",
    "Without interaction: Sales predictions are based solely on the separate effects of each advertising type.\n",
    "With interaction: This model considers the combined impact of both advertising methods, adjusting for situations where the effect of TV spending is influenced by online spending (and vice versa).\n",
    "2) Modifying the Formulas for Binary Predictor Variables\n",
    "Binary Variables:\n",
    "Classify high/low budgets as binary variables for TV (D1) and online (D2) advertising.\n",
    "Linear Equations with Binary Predictors:\n",
    "Without Interaction:\n",
    "Y=β0+β1D1+β2D2\n",
    "With Interaction:\n",
    "Y=β0+β1D1+β2D2+β3(D1⋅D2)\n",
    "Explanation of Predictions:\n",
    "Without interaction: Sales predictions are made by evaluating each high/low budget separately.\n",
    "With interaction: This model incorporates an effect for instances where both TV and online budgets are high, capturing any additional influence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c35550f",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "Data Preparation and Creation of a Binary Outcome\n",
    "To begin, you should:\n",
    "Import your dataset from the Canadian Social Connection Survey.\n",
    "Select a categorical outcome variable to convert into a binary outcome. For example, if you have a variable such as “ConnectionLevel” with several categories (like “High,” “Moderate,” “Low”), you could create a binary variable that distinguishes between “High” and “Not High.”\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Example of turning a categorical outcome into binary, assuming \"ConnectionLevel\" has levels\n",
    "data['HighConnection'] = (data['ConnectionLevel'] == 'High').astype(int)\n",
    "\n",
    "Logistic Regression Model with Additive Specification\n",
    "In logistic regression, you will define a formula that integrates various continuous, binary, and/or categorical variables as predictors. \n",
    "Here’s an example of Additive Specification (excluding interaction terms):\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Specify the logistic regression formula\n",
    "formula_additive = 'HighConnection ~ ContinuousVar1 + ContinuousVar2 + BinaryVar + C(CategoricalVar)'\n",
    "\n",
    "# Fit the logistic regression model\n",
    "log_reg_model_additive = smf.logit(formula_additive, data=data).fit()\n",
    "print(log_reg_model_additive.summary())\n",
    "\n",
    "In this context, ContinuousVar1, ContinuousVar2, BinaryVar, and CategoricalVar serve as placeholders. You should substitute them with the specific names of your variables. The C() function is used to convert a categorical predictor variable that has multiple categories into binary indicator variables for each category. \n",
    "\n",
    "Logistic Regression Model with Interaction (Synergistic Specification) \n",
    "Next, incorporate interaction terms. This allows for the investigation of whether specific combinations of predictors influence the outcome more significantly than what would be anticipated based on their separate effects.\n",
    "\n",
    "# Specify the logistic regression formula with interaction terms\n",
    "formula_interaction = 'HighConnection ~ ContinuousVar1 * BinaryVar + ContinuousVar2 * C(CategoricalVar)'\n",
    "\n",
    "# Fit the logistic regression model with interactions\n",
    "log_reg_model_interaction = smf.logit(formula_interaction, data=data).fit()\n",
    "print(log_reg_model_interaction.summary())\n",
    "\n",
    "Understanding Logistic Regression Models\n",
    "The coefficients in logistic regression indicate changes in log odds instead of direct outcome values. Although interpreting log odds can be challenging, here’s a more straightforward method: \n",
    "Consider these coefficients like those in linear regression. A positive coefficient suggests that higher values of the predictor increase the probability of the outcome being 1 (for instance, a “High” connection level), while a negative coefficient indicates the opposite effect. \n",
    "If interactions are significant, it means that the impact of one variable on the outcome is influenced by the level of another variable. \n",
    "The .summary() output provides the estimated coefficients, their significance, and additional metrics to evaluate whether each predictor has a statistically significant effect.\n",
    "\n",
    "Visualizing Logistic Regression Outcomes\n",
    "With plotly, you can create visual representations to demonstrate the logistic regression “fit.” For a continuous predictor variable paired with a binary predictor, plot the predicted probability curve of the logistic model (akin to a “best fit line” in linear regression) for both the additive and interaction models.\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Generate a range of values for the continuous predictor\n",
    "x_range = np.linspace(data['ContinuousVar1'].min(), data['ContinuousVar1'].max(), 100)\n",
    "\n",
    "# Predict probabilities using the additive model\n",
    "data['pred_prob_additive'] = log_reg_model_additive.predict(data)\n",
    "\n",
    "# Plot with continuous predictor and binary indicator (additive)\n",
    "fig_additive = px.scatter(data, x='ContinuousVar1', y='HighConnection', \n",
    "                          trendline=\"ols\", title=\"Additive Model Prediction\")\n",
    "fig_additive.update_traces(mode='markers+lines')\n",
    "fig_additive.show()\n",
    "\n",
    "# Predict probabilities using the interaction model\n",
    "data['pred_prob_interaction'] = log_reg_model_interaction.predict(data)\n",
    "\n",
    "# Plot with continuous predictor and binary indicator (interaction)\n",
    "fig_interaction = px.scatter(data, x='ContinuousVar1', y='HighConnection', \n",
    "                             trendline=\"ols\", title=\"Interaction Model Prediction\")\n",
    "fig_interaction.update_traces(mode='markers+lines')\n",
    "fig_interaction.show()\n",
    "\n",
    "Additive Plot: Illustrates the impact of the continuous variable on the outcome independently, without considering any interactions.  \n",
    "Interaction Plot: Displays how the joint influence of both continuous and binary variables affects the outcome.  \n",
    "\n",
    "Analyzing Plots and the Need for Interaction  \n",
    "Examine the additive model plot to assess whether there is a clear relationship between the predictor and the outcome. Analyze the interaction plot to see if there is a noticeable change when the interaction is included. A significant shift in the curve for varying values of the binary variable may suggest that an interaction is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bb4fc",
   "metadata": {},
   "source": [
    "4.\n",
    "\n",
    "Understanding R² and Its Significance\n",
    "R², also known as the coefficient of determination, quantifies the extent to which the variability in the outcome variable is accounted for by the model's predictors. For instance, if we state that \"the model explains only 17.6% of the variability in the data,\" it indicates that the model has a low explanatory capacity. This implies that 82.4% of the variability in the outcome remains unexplained by the predictors in the model, which could mean:\n",
    "There is considerable random variation in the outcome variable.\n",
    "There may be significant predictors that are not included in the model.\n",
    "\n",
    "Understanding p-Values and Their Significance\n",
    "p-values help us assess whether the estimated effect of each predictor is statistically significant, considering all other predictors in the model. When p-values are low (generally below 0.05), it suggests strong evidence that the predictor is related to the outcome variable in a way that is unlikely to be random. Therefore, when we observe large, significant coefficients, it indicates that these predictors have a meaningful association with the outcome while controlling for other predictors, even though the model itself has limited capacity to explain the overall variability in the outcome.\n",
    "\n",
    "Why Large, Significant Coefficients Can Coexist with Low R²\n",
    "\n",
    "P-values indicate the reliability of individual coefficient estimates: Even if the overall model explains little variability (low R²), specific predictors can still show statistically significant effects. This occurs when those predictors consistently influence the outcome, despite the overall impact being minimal.\n",
    "\n",
    "A low R² can signify considerable unexplained variation: A low R² often results from the outcome variable having significant natural variability or noise that the predictors do not account for. This does not imply that the predictors lack genuine effects; rather, it suggests that their combined influence does not encompass all sources of variation.\n",
    "\n",
    "Different Emphases of R² and P-values:\n",
    "R² assesses the overall fit of the model, indicating how much of the outcome's variability can be predicted by it.\n",
    "P-values evaluate the significance of each predictor's relationship with the outcome, considering the presence of other predictors.\n",
    "\n",
    "Illustrative Example\n",
    "Consider a model that predicts test scores based on study hours, sleep hours, and exercise habits. Even if study hours have a strong, significant impact on test scores, the model's R² could still be low if factors like natural ability or other uncontrolled variables (such as tutoring) significantly affect test score variability. In this case, a strong individual effect does not imply that the overall model explains much about the outcome.\n",
    "\n",
    "How to Analyze Both Metrics Together\n",
    "When both metrics are presented, interpret them as follows:\n",
    "Large, significant coefficients (low p-values): Indicate that these predictors significantly affect the outcome, even if they do not account for all the variability.\n",
    "Low R²: Suggests that the model fails to explain a large portion of the outcome's total variability. This may imply that additional predictors are necessary or that there is inherent noise or randomness in the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7558b30b",
   "metadata": {},
   "source": [
    "Smmary: Here’s a summary of the key points discussed:\n",
    "\n",
    "1. **Difference between Simple and Multiple Linear Regression**:\n",
    "   - **Simple Linear Regression** involves one predictor and one outcome variable, with a linear relationship in the form: \\( Y = \\beta_0 + \\beta_1X \\).\n",
    "   - **Multiple Linear Regression** involves two or more predictors, allowing more complex relationships: \\( Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_nX_n \\).\n",
    "   - **Advantage of Multiple Regression**: It captures the combined effects of multiple predictors, leading to potentially better predictions and a deeper understanding of how different factors influence the outcome.\n",
    "\n",
    "2. **Continuous vs. Indicator Variables in Regression**:\n",
    "   - A **continuous variable** provides a range of values and allows us to assess the change in the outcome per unit change in the predictor.\n",
    "   - An **indicator (binary) variable** represents categorical data (e.g., “Yes” or “No”) and can show differences between categories in the regression model.\n",
    "   - Introducing an indicator variable allows for modeling categorical differences in an otherwise linear regression context.\n",
    "\n",
    "3. **Effect of Adding an Indicator Variable in Multiple Regression**:\n",
    "   - Adding an indicator variable alongside a continuous variable can allow the model to capture differences between groups while accounting for trends within each group. The form changes to include both variables: \\( Y = \\beta_0 + \\beta_1X + \\beta_2D \\), where \\( D \\) is the indicator.\n",
    "\n",
    "4. **Interaction Terms**:\n",
    "   - **Continuous x Indicator Interaction**: An interaction term between a continuous and an indicator variable (e.g., \\( Y = \\beta_0 + \\beta_1X + \\beta_2D + \\beta_3(X \\times D) \\)) allows the effect of the continuous variable on the outcome to differ across groups.\n",
    "   - **Continuous x Continuous Interaction**: This type of interaction (e.g., \\( Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3(X_1 \\times X_2) \\)) captures how the effect of one predictor changes depending on the level of another.\n",
    "\n",
    "5. **Categorical Variables with Multiple Levels**:\n",
    "   - When using a categorical variable with multiple levels, it’s represented by **indicator (binary) variables** for each category except one baseline (reference) category.\n",
    "   - The baseline represents the reference group, and each indicator variable shows the effect of being in a specific category relative to the baseline.\n",
    "\n",
    "6. **Logistic Regression for Binary Outcomes**:\n",
    "   - In logistic regression, the model predicts the log odds of a binary outcome. It’s particularly useful for categorical outcomes and can be specified with additive and interaction terms, similar to linear regression.\n",
    "\n",
    "7. **Interpreting R-squared and p-values Together**:\n",
    "   - **\\( R^2 \\)** shows the proportion of variability explained by the model, while **p-values** assess the significance of individual predictors.\n",
    "   - A low \\( R^2 \\) with significant predictors suggests that although individual predictors have meaningful effects, much of the variability in the outcome is due to other factors.\n",
    "   - These measures are not contradictory; they address different aspects: \\( R^2 \\) for overall model fit, and p-values for predictor significance.\n",
    "\n",
    "This overview should help you understand each concept and apply it to your analysis or interpretation of regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c7359",
   "metadata": {},
   "source": [
    "Link: https://chatgpt.com/share/673304ae-a34c-800e-88da-91f00575fd11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba24c54a",
   "metadata": {},
   "source": [
    "5.\n",
    "\n",
    "Cell 1)\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0] * 0.5)\n",
    "\n",
    "\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "\n",
    "Purpose: This cell is preparing the dataset for model training and evaluation.\n",
    "Key Operations:\n",
    "Missing values in the Type 2 column are replaced with 'None' to handle any missing data.\n",
    "A 50-50 split is applied to the dataset to create a training set (pokeaman_train) and a testing set (pokeaman_test).\n",
    "The random seed ensures the train-test split is reproducible.\n",
    "\n",
    "Cell 2)\n",
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()\n",
    "\n",
    "Purpose: This cell fits a simple linear regression model (Model 3) that predicts the HP variable using Attack and Defense as predictors.\n",
    "Key Operations:\n",
    "The formula HP ~ Attack + Defense specifies the relationship between the dependent (HP) and independent variables (Attack, Defense).\n",
    "The model is fit using the pokeaman_train data.\n",
    "The .summary() provides detailed statistics about the model fit, including R-squared, p-values, and coefficients.\n",
    "\n",
    "Cell 3)\n",
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model3)[0, 1]**2)\n",
    "\n",
    "Purpose: This cell evaluates Model 3's performance on both the training set and the test set.\n",
    "Key Operations:\n",
    "In-sample R-squared: model3_fit.rsquared measures how well the model fits the training data. It tells us the proportion of variation in HP that is explained by the model using Attack and Defense.\n",
    "Out-of-sample R-squared: The predictions from the test set (yhat_model3) are compared to the actual HP values in pokeaman_test. The squared correlation between the predicted and actual values gives the out-of-sample R-squared, which assesses how well the model generalizes to unseen data.\n",
    "\n",
    "Cell 4)\n",
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()\n",
    "\n",
    "Purpose: This cell fits a complex linear regression model (Model 4) with more predictors and interaction terms.\n",
    "Key Operations:\n",
    "The formula for Model 4 is more complex, including interaction terms between multiple predictors like Attack, Defense, Speed, Legendary, Sp. Def, and Sp. Atk.\n",
    "It is important to note that some terms (such as Generation, Type 1, and Type 2) have been excluded to prevent computational issues due to excessive interaction terms.\n",
    "The model is fit using the training set (pokeaman_train), and the .summary() function provides detailed statistics, similar to Model 3.\n",
    "\n",
    "Cell 5)\n",
    "\n",
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model4)[0, 1]**2)\n",
    "\n",
    "Purpose: This cell evaluates the performance of Model 4 on both the training and testing data, similar to how Model 3 was evaluated.\n",
    "Key Operations:\n",
    "In-sample R-squared: model4_fit.rsquared shows how well the complex model fits the training data.\n",
    "Out-of-sample R-squared: The predicted HP values (yhat_model4) are compared to the actual HP values in the test set, with the squared correlation providing the out-of-sample R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4ac20",
   "metadata": {},
   "source": [
    "6.\n",
    "\n",
    "Grasping Multicollinearity and Its Impact on Model Generalization\n",
    "Design Matrix and Predictor Variables\n",
    "In linear regression, the design matrix (model4_spec.exog) includes the predictor variables that are utilized to forecast the outcome variable (model4_spec.endog). This design matrix is structured as a table, with each column representing a predictor variable (or its transformation), and each row representing an observation. In Model 4, the linear structure incorporates a collection of predictors that include interactions, such as:\n",
    "\n",
    "HP ~ Attack * Defense * Speed * Legendary * Q(\"Sp. Def\") * Q(\"Sp. Atk\")\n",
    "\n",
    "This means we have:\n",
    "Attack, Defense, Speed, and other predictors.\n",
    "Interaction terms between these predictors (e.g., Attack * Defense, Attack * Speed, etc.).\n",
    "The presence of categorical variables (e.g., Legendary) and transformations (e.g., Q(\"Sp. Def\")).\n",
    "The exog matrix (model4_spec.exog) will contain all the main effects and interaction terms, expanding the number of columns (predictors). This large number of predictors often leads to multicollinearity.\n",
    "\n",
    "Multicollinearity and Its Effects\n",
    "Multicollinearity arises when there are strong correlations among certain predictors in the design matrix, indicating that some predictors are closely related or even linear combinations of others. In Model 4, interaction terms (like Attack * Defense or Speed * Legendary) can introduce multicollinearity, as these combinations may not provide significant new information. For example, if Attack and Defense are already highly correlated, their interaction term may be redundant or nearly so.\n",
    "\n",
    "When predictors are highly correlated, the model struggles to identify their individual impacts on the outcome variable (HP), leading to unstable coefficient estimates and increased variance for the regression coefficients.\n",
    "\n",
    "Condition Number and Model Effectiveness\n",
    "The condition number serves as an indicator of multicollinearity within the design matrix. A high condition number suggests significant multicollinearity, which can complicate the estimation of model parameters. The summary output includes the \"Cond. No.\" (condition number) for evaluation:\n",
    "Before adjusting the predictors through centering and scaling, Model 3 had a condition number of 343, which is moderately high.\n",
    "After these adjustments, the condition number for Model 3 decreased to 1.66, indicating a reduction in multicollinearity.\n",
    "However, for Model 4, even after centering and scaling the predictors, the condition number remains extremely high:\n",
    "The condition number post-adjustment is 2,250,000,000,000,000, a significantly large figure that indicates severe multicollinearity.\n",
    "\n",
    "Effects on Generalization\n",
    "Multicollinearity negatively impacts the model's performance on unseen data, leading to overfitting. The model captures the noise in the data rather than the actual underlying relationships, making it overly sensitive to minor variations in the test data. \n",
    "\n",
    "The elevated condition number suggests that the model is overfitting the training data, which hampers its ability to generalize to new, unseen data (resulting in poorer out-of-sample performance). Consequently, predictions made by the model on new data (test data) will exhibit weak generalization compared to the training data, with the out-of-sample R-squared being lower than the in-sample R-squared.\n",
    "\n",
    "Concise Explanation\n",
    "The design matrix in Model 4 is large, with many predictors and interaction terms, which leads to multicollinearity. This occurs when predictors are highly correlated, making it difficult for the model to distinguish their individual effects. Despite centering and scaling the predictors, the condition number remains very high, indicating severe multicollinearity. This multicollinearity causes the model to overfit the training data, leading to poor out-of-sample generalization. The model's predictions on new data are less accurate because the model has learned noise in the training data rather than meaningful patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a241c9f",
   "metadata": {},
   "source": [
    "7.\n",
    "\n",
    "Rationale and Principles of Developing Model Forms\n",
    "In this series of models, each new linear form (model5_linear_form, model6_linear_form, model7_linear_form) is developed from the previous one by adding new predictors or transformations. Let's break down how each model builds on the previous one:  \n",
    "\n",
    "Model 5: Building on Model 4\n",
    "Development: Model 5 enhances the previous model by incorporating a wider range of predictors. It retains the predictors from Model 4 (such as Attack, Defense, Speed, Special Defense, Special Attack, and Legendary status) and introduces categorical variables like Generation, Type 1, and Type 2. These new features aim to capture more intricate relationships between the outcome variable HP and various factors, ultimately improving prediction accuracy.\n",
    "Specifically:\n",
    "C(Generation): This represents the categorical variable Generation, treating different Pokémon generations as distinct predictors.\n",
    "C(Q(\"Type 1\")) and C(Q(\"Type 2\")): These denote the two categorical features for Pokémon types, which are converted into binary indicator variables (dummy variables).\n",
    "Goal: The purpose of this expansion is to incorporate more detailed categorical interactions that could affect HP, thereby enhancing predictive performance.\n",
    "\n",
    "Model 6: Streamlining and Incorporating Key Indicators\n",
    "Development: Model 6 simplifies Model 5 by narrowing down the number of predictors. It concentrates on a more select group of predictors: Attack, Speed, Special Defense, and Special Attack. It also retains significant indicators from Model 5, such as:\n",
    "I(Q(\"Type 1\")==\"Normal\") and I(Q(\"Type 1\")==\"Water\"): These binary indicators identify specific Pokémon types, aiming to enhance predictions for particular types.\n",
    "I(Generation==2) and I(Generation==5): These indicators focus on specific generations (2 and 5), which are pertinent for certain Pokémon types based on the dataset.\n",
    "Goal: The intention here is to emphasize the most impactful features while keeping the relevant categorical indicators. This simplification can help mitigate overfitting by concentrating on the most significant predictors.\n",
    "\n",
    "Model 7: Incorporating Interaction Terms for Enhanced Flexibility\n",
    "Development: Model 7 adds interaction terms among predictors to better capture intricate relationships between features. The interaction terms involve Attack, Speed, Sp. Def, and Sp. Atk:\n",
    "Interaction Terms: By incorporating interaction terms like Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\"), the model can account for the combined influence of these predictors on HP, revealing more nuanced dependencies.\n",
    "The categorical indicators from Model 6 are preserved.\n",
    "Goal: The introduction of interaction terms enhances the model's ability to represent non-linear relationships among predictors, facilitating a more accurate representation of complex interactions within the data.\n",
    "Model 7 with Centering and Scaling (Model7_CS)\n",
    "Development: Model 7 is further refined by centering and scaling the continuous predictors (Attack, Speed, Sp. Def, Sp. Atk) to standardize their scale and mitigate issues like multicollinearity. The categorical variables (indicators) remain unscaled, as they are binary and do not require scaling.\n",
    "Centering: This involves subtracting the mean of each continuous variable to ensure the data has a mean of zero.\n",
    "Scaling: This entails dividing by the standard deviation to ensure all predictors have a unit variance.\n",
    "Goal: Centering and scaling the continuous variables enhances the model’s numerical stability (as indicated by a lower condition number) and improves interpretability, as the scaled values indicate how many standard deviations they are from the mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9baf80",
   "metadata": {},
   "source": [
    "8.\n",
    "\n",
    "Objective of the Demonstration\n",
    "The objective of this demonstration is to examine the behavior of in-sample and out-of-sample model performance metrics when various random data splits are utilized for training and testing. We specifically want to analyze the fluctuations in R-squared values (both \"in-sample\" and \"out-of-sample\") across different iterations. This will help us understand the consistency of the model's predictions and its ability to generalize to new, unseen data. \n",
    "\n",
    "In a model that performs well, we anticipate that the in-sample and out-of-sample R-squared values will be fairly similar, indicating good generalization. A large discrepancy between the two may suggest that the model is overfitting the training data.\n",
    "\n",
    "Code:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Initialize lists to store results\n",
    "in_sample_r2 = []\n",
    "out_of_sample_r2 = []\n",
    "\n",
    "# Loop for multiple random splits\n",
    "for i in range(100):  # Run 100 iterations\n",
    "    # Split data randomly without fixing the seed\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Fit model with selected predictors (Model 3 example)\n",
    "    model_spec3 = smf.ols(formula='HP ~ Attack + Defense', data=pokeaman_train)\n",
    "    model3_fit = model_spec3.fit()\n",
    "    \n",
    "    # 'In-sample' R-squared (based on training data)\n",
    "    in_sample_r2.append(model3_fit.rsquared)\n",
    "    \n",
    "    # 'Out-of-sample' R-squared (based on testing data)\n",
    "    yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "    y = pokeaman_test.HP\n",
    "    out_of_sample_r2.append(np.corrcoef(y, yhat_model3)[0, 1]**2)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(in_sample_r2, label=\"In-sample R-squared\", alpha=0.7)\n",
    "plt.plot(out_of_sample_r2, label=\"Out-of-sample R-squared\", alpha=0.7)\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.title(\"In-sample vs. Out-of-sample R-squared Across Iterations\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"R-squared\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "Code Explanation:\n",
    "For Loop: We execute a loop 100 times to create various random splits of the dataset using train_test_split(). Each split divides the data into 50% for training and 50% for testing, with randomness introduced by not setting np.random.seed(130) within the loop.\n",
    "Model Fitting: In each iteration, we fit the model (HP ~ Attack + Defense) using the training dataset (pokeaman_train) and then compute two metrics:\n",
    "In-sample R-squared: This metric is obtained directly from the model via model3_fit.rsquared, indicating how well the model fits the training data.\n",
    "Out-of-sample R-squared: This is calculated by predicting the test data (pokeaman_test) and determining the squared correlation between the actual and predicted HP values.\n",
    "Storing Results: The lists in_sample_r2 and out_of_sample_r2 gather the R-squared values from each iteration.\n",
    "Plotting: Finally, we visualize the in-sample and out-of-sample R-squared values across all iterations. This helps in assessing the model's consistency and generalizability across different random splits.\n",
    "Results Interpretation:\n",
    "In-sample R-squared: This indicates how well the model fits the training data. A high in-sample R-squared is anticipated, but it does not ensure that the model will generalize to new data.\n",
    "Out-of-sample R-squared: This metric assesses the model’s ability to generalize to unseen data (the test set). A high out-of-sample R-squared implies that the model is not overfitting and can make accurate predictions on new data.\n",
    "Expected Trends:\n",
    "If the model is overfitting, the in-sample R-squared will significantly exceed the out-of-sample R-squared across iterations.\n",
    "If the model generalizes effectively, both R-squared values should be fairly close.\n",
    "Variability: As we are not using a fixed random seed, each iteration will yield slightly different splits, leading to fluctuations in the R-squared values. However, consistent trends or notable differences can provide insights into the model's performance.\n",
    "\n",
    "In conclusion, this demonstration enables us to see how model performance varies with different random divisions of the dataset. By looking at the R-squared values for both in-sample and out-of-sample data, we can determine if the model is reliable and can generalize well, or if it is simply fitting too closely to the training data. The changes in these values emphasize the need for employing cross-validation or similar methods to evaluate model performance more comprehensively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02d834",
   "metadata": {},
   "source": [
    "9.\n",
    "\n",
    "Illustration Overview:\n",
    "The provided code focuses on developing regression models to estimate the HP (hit points) of Pokémon based on various characteristics, particularly examining the impact of different Pokémon \"generations\" on these predictions. The objective is to evaluate the effectiveness of these models in predicting HP for Pokémon from different \"generations,\" specifically Generation 1, and then for Generations 1 through 5, while comparing the in-sample and out-of-sample R-squared values.\n",
    "\n",
    "Code Breakdown:\n",
    "Model for Generation 1 Pokémon:\n",
    "The model named model7_gen1_predict_future is created using only Generation 1 Pokémon data. The in-sample R-squared is determined for this model based on Generation 1 data. The out-of-sample R-squared is calculated by predicting HP values for Pokémon from other generations and comparing these predictions to the actual HP values in the test dataset (pokeaman_test).\n",
    "\n",
    "Model for Pokémon from Generations 1 to 5:\n",
    "The model model7_gen1to5_predict_future is developed using data from Generations 1 to 5. The in-sample R-squared is computed using this data, while the out-of-sample R-squared is assessed for Generation 6 Pokémon, which were not included in the training dataset.\n",
    "\n",
    "Model for Generation 1 with Model 6 Specification:\n",
    "Similar to the previous models, model6_gen1_predict_future fits a model for Generation 1 Pokémon using a different set of predictors (model6_linear_form). The R-squared values are calculated in the same manner: in-sample for Generation 1 and out-of-sample for the remaining Pokémon.\n",
    "\n",
    "Model for Pokémon from Generations 1 to 5 with Model 6 Specification:\n",
    "The model model6_gen1to5_predict_future is fitted on data from Generations 1 to 5 and is evaluated using Generation 6 Pokémon. The results demonstrate how effectively the model generalizes to new data.\n",
    "\n",
    "Key Takeaways:\n",
    "In-sample R-squared: This indicates how well the model fits the training data, with a higher value signifying a better fit.\n",
    "Out-of-sample R-squared: This assesses the model's ability to generalize to new, unseen data (the test set), with a higher value suggesting better performance on future or unseen data.\n",
    "\n",
    "Interpretation:\n",
    "Generation 1 Models: A model trained solely on Generation 1 Pokémon is likely to show strong performance (high in-sample R-squared) within that specific group. However, its effectiveness in predicting Pokémon from other generations (out-of-sample R-squared) may be limited. This indicates that the model is specifically designed to recognize patterns in Generation 1 data and may not account for broader trends found in subsequent generations.\n",
    "\n",
    "Generations 1 to 5 Models: By expanding the training dataset to include Pokémon from Generations 1 to 5, the model may achieve better performance on data from those generations (in-sample). However, its ability to predict Generation 6 Pokémon (which were not included in the training) is evaluated to determine its generalizability. A lower out-of-sample R-squared for Generation 6 could imply that the model has difficulty predicting data that diverges from the patterns established in earlier generations.\n",
    "\n",
    "Model 6 Specification: Comparing models with different predictor sets (e.g., model7_linear_form vs. model6_linear_form) illustrates how the addition of various features (such as Attack, Defense, Speed, and Pokémon type indicators) can affect model performance. A model that incorporates more relevant features may yield better results in both in-sample and out-of-sample evaluations, although there is still a risk of overfitting.\n",
    "\n",
    "Purpose of the Experiment:\n",
    "The goal of this experiment is to assess how effectively models trained on specific data subsets (like only Generation 1 Pokémon or Generations 1 to 5) can predict HP for Pokémon from other generations. The experiment evaluates model generalizability by comparing in-sample and out-of-sample R-squared values. A significant disparity between a model's in-sample and out-of-sample performance may indicate overfitting, where the model memorizes the training data but struggles to generalize to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aea6d5",
   "metadata": {},
   "source": [
    "Summary:\n",
    "Here’s a concise summary of everything you've asked:\n",
    "\n",
    "### 1. **Initial Analysis and Model Building**:\n",
    "You worked on a series of models to predict the `HP` (hit points) of Pokémon based on various features. The models use the `pokeaman` dataset, which includes columns such as `Attack`, `Defense`, `Speed`, and `Legendary` status, among others. You initially split the dataset into training and testing sets, then built multiple models (e.g., `model3_fit`, `model4_fit`) using **ordinary least squares (OLS)** regression, with different combinations of predictors.\n",
    "\n",
    "Key aspects:\n",
    "- **Handling missing data**: You replaced missing values in the dataset (`NaN`) with \"None\".\n",
    "- **Model complexity**: Models grew more complex, including interactions between variables and categorical features (e.g., Pokémon `Type 1`, `Type 2`, and `Generation`).\n",
    "- **Multicollinearity**: Some models had issues with multicollinearity (high correlations between predictor variables), which could harm the model's generalizability.\n",
    "\n",
    "### 2. **Model Scaling and Centering**:\n",
    "You experimented with centering and scaling the predictor variables to address multicollinearity, especially in models that involved interaction terms. This was meant to improve the **condition number** (a measure of multicollinearity), making the model more stable.\n",
    "\n",
    "- **Condition number**: After scaling, the condition number decreased significantly (from very high values), but it remained problematic in some cases.\n",
    "\n",
    "### 3. **Performance Evaluation**:\n",
    "You evaluated the models by calculating **in-sample** and **out-of-sample R-squared values**:\n",
    "- **In-sample R-squared** measures how well the model fits the training data.\n",
    "- **Out-of-sample R-squared** evaluates the model's generalizability using test data.\n",
    "\n",
    "You demonstrated how **overfitting** could occur when a model fits the training data too well but performs poorly on unseen data. This was particularly evident when comparing models built on subsets of the data (e.g., Generation 1 Pokémon).\n",
    "\n",
    "### 4. **Iterative Model Development**:\n",
    "- You extended `model4_fit` into `model5_fit`, `model6_fit`, and `model7_fit`, progressively adding more predictors (e.g., specific Pokémon types, indicator variables for certain generations).\n",
    "- These models represented an attempt to improve generalizability and predictive accuracy by incorporating more relevant features.\n",
    "- **Interactions** were added in `model7_fit`, which included interaction terms for `Attack`, `Speed`, `Sp. Def`, and `Sp. Atk`.\n",
    "\n",
    "### 5. **Cross-Generation Prediction**:\n",
    "You explored how well models trained on certain generations (e.g., Generation 1) could generalize to other generations. For example, you:\n",
    "- Fitted a model on **Generation 1 Pokémon** and tested it on the rest of the generations to assess **out-of-sample R-squared**.\n",
    "- Built models using data from **Generations 1 to 5** and tested on **Generation 6**.\n",
    "\n",
    "The goal was to see how well the model trained on one generation of Pokémon could predict HP for other generations and evaluate whether the model could generalize across generations.\n",
    "\n",
    "### 6. **Purpose and Interpretation**:\n",
    "- **In-sample vs. Out-of-sample**: The key takeaway was understanding how the performance on training data (`in-sample`) might not reflect the model's performance on new, unseen data (`out-of-sample`). If the model fits the training data too closely (overfitting), it may fail to generalize.\n",
    "- **Multicollinearity and Generalizability**: Models with severe multicollinearity can overfit the data, as seen with high condition numbers, and struggle to generalize well to other datasets.\n",
    "- **Model Extension**: As you added more features and interaction terms, the models became increasingly complex, and you explored their ability to generalize to new data through cross-validation techniques (e.g., testing on different Pokémon generations).\n",
    "\n",
    "This work highlighted important concepts in statistical modeling, including **multicollinearity**, **overfitting**, and **generalizability**, and demonstrated how different model specifications and transformations (e.g., scaling, centering) affect predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c8d7a",
   "metadata": {},
   "source": [
    "Link: https://chatgpt.com/share/67330b60-3014-800e-96fe-3f9728f2b389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19460ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
